# 2023.7 - Substrate 技术更新速递

## 重要提交和发布

1. [chainHead_storage: Iterate over keys](https://github.com/paritytech/substrate/pull/14628): 本次提交增加了对（键，值）和（键，哈希）对的迭代支持。目前，substrate最多会迭代10个键，产生最多10对键值对。此次提交为迭代提供了基础，并且将在[RPC-Spec-V2] Storage: Add support for pagination #14549中增加对分页的支持。新的测试检查了API可以接收多个项目作为参数，以及（键，值）和（键，哈希）上的迭代如预期工作。此次提交解决了#14548问题。

2. [Relax Send/Sync/Clone requirements for Pair](https://github.com/paritytech/substrate/pull/14647)：这个PR主要关注了对`Pair` trait的Send/Sync/Clone需求的放宽。以下是主要的变更和讨论内容：

   - 在代码库中，秘密信息通常会尽快被构造和销毁，这是一个安全的做法。在某些情况下，Send/Sync/Clone的约束可能会有害；一些组件可能需要秘密信息不在线程间共享（实际上是在没有清理前一个位置的情况下悄悄地移动到另一个堆栈）或被克隆（例如，在后端没有实现类似zeroize的清理内存的情况下）。

   - 一些即将到来的后端提供的秘密信息可能不允许这些约束。例如，即将到来的Bandersnatch ring-vrf秘密信息就不是Sync的。因此，对于这个trait约束，选择空间并不大。

   - 目前，这些约束在AURA代码中是无条件需要的。在这里，一些组件是关于键类型的泛型，这些组件需要是Send的。然而，Pair并不是组件结构实例的一部分，泛型只被用作一个特定键类型和因此权限id类型的约束（即，这些结构包含一个PhantomData<Pair>）。

   - 这个问题可以通过使用PhantomData<fn() -> Pair>代替PhantomData<Pair>来轻松解决。PhantomData<fn() -> Pair>既是Send也是Sync的（无论Pair的约束如何）。也就是说，带有PhantomData的类型并不拥有Pair，而是可以潜在地产生Pairs（这是一个重大的区别）。

   - 此外，PR还包含了一些微小的清理和可能的其他约束的移除。

3. [移除执行策略](https://github.com/paritytech/substrate/pull/14387)：这个PR主要关注了移除执行策略。执行策略决定了Runtime调用的执行方式，例如，仅使用wasm运行时，仅使用原生Runtime，或者两者的组合。但是，随着原生Runtime的移除，选择执行策略将变得无关紧要，因为唯一可以选择的策略将是“仅wasm”。这个PR也引入了Runtime API的行为变化。在这之前，基于给Runtime调用的上下文，可能已经传递了自定义的“能力”，这些能力决定了Runtime调用可以访问哪种类型的执行扩展。现在，所有这些默认都不可用。这意味着，当你有一些代码想要从Runtime调用提交交易时，交易池需要手动注册为Runtime API实例的执行扩展。此外，这个PR移除了`build_offchain_workers`函数，使得offchain worker的初始化对用户更“明显”。为了生成offchain worker，需要在服务文件中添加特定的代码。最后，这个PR改变了Grandpa和BABE客户端包的一些参数和签名，以适应新的执行策略和offchain tx pool factory。

4. [避免导入不必要的GRANDPA证明](https://github.com/paritytech/substrate/pull/14423)：此PR主要关注了在导入区块时如何处理包含的GRANDPA证明。在当前的实现中，如果一个区块包含了GRANDPA证明，我们总是会处理它。如果一个节点为我们提供了每个区块的证明，我们将不可避免地验证并导入它们，这可能导致区块导入速度显著降低。我们并不需要每个区块的证明，因此这是一种浪费。在此PR之后，我们将只导入每512个区块的GRANDPA证明（除了强制性的证明，即当权威节点发生变化时）。

5. "[优化存储元数据的表示](https://github.com/paritytech/substrate/pull/14440)：此PR主要关注了如何优化存储元数据的表示。在当前的实现中，存储元数据是以一个大的、连续的、预分配的数组来表示的。这种表示方式在处理大量存储项时可能会导致内存使用效率低下。此PR提出了一种新的表示方式，即使用`BTreeMap`来表示存储元数据，这样可以在添加新的存储项时动态地分配内存，从而提高内存使用效率。

   以下是主要的变更和讨论内容：

   - 将存储元数据的表示方式从数组改为`BTreeMap`。这样做的好处是，`BTreeMap`在添加新的存储项时可以动态地分配内存，而不是像数组那样预先分配一大块内存。这可以在处理大量存储项时提高内存使用效率。

   - 为了实现这一变更，修改了`sp_core::storage::Storage`结构，将其`top`字段的类型从`Vec<(Vec<u8>, Vec<u8>)>`改为`BTreeMap<Vec<u8>, Vec<u8>>`。

   - 在`sp_core::storage::Storage`结构中添加了一个新的方法`insert_or_update`，用于向存储中添加或更新一个项。

   - 在`sp_core::storage::Storage`结构中添加了一个新的方法`remove`，用于从存储中移除一个项。

   - 在`sp_core::storage::Storage`结构中添加了一个新的方法`contains_key`，用于检查存储中是否包含指定的键。

6. [重构资产转换交易支付模块](https://github.com/paritytech/substrate/pull/14558)：此PR主要关注了对资产转换交易支付模块的重构。以下是主要的变更和讨论内容：

   - 将`SwapNative`从`fungibles`中移动到一个`Swap` trait，并将其放置在资产转换模块中。这样做的目的是为了减少代码重复，并使得`Swap` trait的方法现在接受一个路径参数，而不仅仅是一个资产。

   - 在实现`Swap` trait时，我们使用`T::HigherPrecisionBalance`而不是`Balance`或`AssetBalance`。这种方法应该比仅限制为一种余额类型并稍后处理转换更具通用性。

7. "[修复资产转换中的get_pool_id问题（Ord不考虑is_native标志）](https://github.com/paritytech/substrate/pull/14572)：此PR主要解决了在资产转换中get_pool_id的问题。以下是主要的变更和讨论内容：

   - PR包含了get_pool_id的主要修复（Ord不考虑is_native标志）。这意味着在系统平行链上，我们不能使用MultiLocation::parent()作为本地资产，因为MultiLocation { parents: 1, ..} > MultiLocation { parents: 0, ..}（parents: 0是系统平行链上的某个本地资产）。

   - PR改进了MultiAssetIdConverter的处理，例如，增加了运行时过滤支持资产等功能。

## 设计方案和问题讨论

1. [FRAME/Meta/PM \"experimental\" FRAME特性](https://github.com/paritytech/substrate/issues/14345)：此议题提出了在FRAME中引入新特性的想法，这些新特性被标记为\"experimental\"。这样做的目的是在不破坏语义版本控制的前提下，开始集成这些新特性，从而加快开发速度。在此议题中，讨论了几种可能的实现方式：

   - A) 使用类似于frame_unstable(id)的属性宏，以及匹配的allow_unstable(id)，其中ID是议题的标识符，类似于rust nightly特性。这是一种更精细、更优雅的解决方案，尽管不确定在没有类似allow(deprecated)的粗粒度情况下如何实现。
   - B) Rust编译器特性，其中我们有一个特性用于保护所有不稳定的特性。
   - C) 最简单的方法是在frame_support中有一个unstable模块，该模块导出所有不稳定的类型。或者在未来只有frame::unstable。不稳定的特性不应通过其他路径访问。我们可以在frame_support中做到这一点，因为模块可以被设置为pub(super)，这样unstable模块就可以导出它们。

2. [集成NFT板块到XCM](https://github.com/paritytech/substrate/issues/14349)：此问题主要关注了如何将pallet-nfts与XCM集成。在当前的实现中，NFTs板块使用NextCollectionId存储，其中存储了下一个集合的CollectionId。每次创建一个集合时，都会计算下一个集合的Id并存储起来。我们需要CollectionId实现Incrementable trait，以便于计算下一个值。然而，为了在NFTs板块中启用衍生NFTs，我们应该能够将CollectionId表示为MultiLocation。例如，中继链上的NFT的衍生物的CollectionId可以表示为Parent/GeneralIndex(x)。但是，当前的NextCollectionId流程不允许这种结构，因为这些MultiLocations没有增量流程。

   以下是主要的讨论和解决方案：

   - 我们添加了一个额外的外部函数，它接受一个collectionId并绕过整个NextCollectionId流程。这个函数如下：
   ```rust
   pub fn create_with_collection_id (
   origin: OriginFor<T>,
   admin: AccountIdLookupOf<T>,
   config: CollectionConfigFor<T, I>,
   collection_id: T::CollectionId,
   ) -> DispatchResult
   ```
   - NFT板块应该在CreateOrigin和ForceOrigin配置类型之上添加CreateCollectionIdOrigin（其他名称也可以），这将限制可以创建具有自定义CollectionIds的集合的Origins。

3. [支持BEEFY协议的实时更新](https://github.com/paritytech/substrate/issues/14606)：此问题主要关注了如何在Polkadot和Ethereum之间的BEEFY协议中实现实时更新。在当前的实现中，如果我们需要进行一次不向后兼容的协议更新，我们需要在Polkadot和Ethereum之间进行大量的协调，这是不理想的。因此，提出了两种可能的解决方案：

   1. 为BEEFY客户端添加支持，使其能够并行运行两个协议版本。这是一个复杂的解决方案，但它允许“无缝”更新，即不会有任何桥接停机时间。首先更新工作节点（验证器客户端），使其能够提供v1和v2的证明，然后通过仍在使用v1的桥接更新轻客户端，最后桥接开始使用v2。

   2. 为pallet-beefy添加支持，以指定当前块中哪个版本是活动的，从而使运行时可以决定客户端（验证器）何时从v1切换到v2。这个解决方案更简单，但可能会导致暂时的停机时间。首先更新工作节点（验证器客户端），使其能够支持v2但仍使用v1，然后通过治理更新轻客户端并设置v2应激活的块号，这两个操作之间的块差异就是“桥接停机时间”。但是，这个差异甚至可以只有1个块，所以在最好的情况下，实际上没有停机时间。

## 文档和资料

1. [ink-docs](https://github.com/paritytech/ink-docs)：这是ink!的文档门户。最新版本始终可在https://use.ink上找到。以下是主要的内容和信息：

   - 你可以在本地通过`yarn`和`yarn start`运行它。对于西班牙语页面，可以通过`yarn start --locale es`访问。
   - 该门户旨在为使用ink!的任何需求提供全面的文档。如果你发现信息有所缺失，或对任何特定区域感到不确定，都可以记录问题或提出拉取请求。
   - 如果你需要在本地主机上运行ReCaptcha，你需要将dev.use.ink添加到你的/etc/hosts中。

2. [Capi文档](https://docs.capi.dev/)：Capi是一个用于与Substrate链进行交互的TypeScript框架。它包括一个开发服务器和流畅的API，可以在不影响性能或易用性的情况下促进多链交互。

   以下是主要的内容和结构：

   - 链资源受到经济激励的有意限制，这决定了链上程序的设计，并限制了应用开发者实现访问模式的能力，这些模式本可以提高最终用户体验。许多此类访问模式执行数据聚合和预处理；在客户端（例如浏览器）上进行这些工作会消耗已经稀缺的资源。在其他情况下，应用开发者可能会将这些任务转移到约束较少的环境，例如集中式服务器。尽管开发者可以使用集中式服务器作为链的代理，但这些中介是可停止性的点。目前还没有明显的解决方案来避免这种权衡。

   - Capi的交互被定义为\"Runes\"，这是描述客户端-链交互的声明性、可移植和强类型的构建块。Runes使得可能复杂的交互可以被折叠成最小的并行化形式，这样Capi开发者就不需要考虑冗余和时序。

   - Capi的设计旨在适应新的技术可能性，而无需开发者付出努力。我们可能会想要：序列化和与其他环境（如RPC节点）共享Runes，这些环境可以协助完成它们以换取微支付；静态分析Runes，以生成最小范围的策略，这些策略将管理会话密钥；生成其他编程语言中的客户端。

3. [Polkadot SDK 文档](https://github.com/paritytech/polkadot-sdk-docs)：这是一个为 Polkadot 开发者提供的全面、简洁的文档门户。以下是主要的内容和特点：

   - 该项目的目标是提供一个全面的教程，目前的计划在 SCRIPT.md 文件中有所描述。这个主题的选择是为了补充 PBA Rust 入门考试中的 mini_substrate 练习中所描绘的图像。

   - 教程的结构是分布在不同的文件夹中，每个独立的步骤都在 tutorial 文件夹的一个文件夹中。

   - 教程的每个步骤在当前状态下只是：实现该步骤所需的代码，以及一个包含如何实现这些的非常高级指令的 README.md 文件。

   - 这些 markdown 文件并不是这个教程的最终版本，而是用来作为后期制作书面教程、幻灯片甚至是一些交互式教程的原材料。

## 技术生态和社区

1. [获奖公布 | 2023 夏季波卡黑客松大赛决赛 DemoDay 圆满落幕](https://mp.weixin.qq.com/s/1xztAjzyEoAYpMMGSfxtYw)：2023 年 7 月 13 日 - 7 月 14 日，2023 夏季波卡黑客松大赛决赛 DemoDay 在上海虹桥国际展汇精彩上演。25 个战队从数百名参赛选手中脱颖而出，共同在这个夏天为我们献上了属于 Hacker 的极致盛宴！2023 夏季波卡黑客松大赛共有 300+ 名参赛选手、80 个战队报名。从五月走到七月，他们为实现在 Web3 的创业探索坚持不懈，来自世界各地的开发者团队共聚上海，用精彩的 Demo 演示诠释了创业者的激情与热血，让所有评委、观众留下了深刻印象，最终获奖名单已经揭晓！

2. [精彩回顾 | Polkadot Decoded 2023 上海站圆满落幕](https://mp.weixin.qq.com/s/5bFtemZaoKP9PJttlflKKA): 波卡年度生态大会 Polkadot Decoded 2023 上海场于 7 月 15 日-16 日在上海虹桥国际展汇顺利举办。行业专家、开发人员、投资人、创业者以及 2023 夏季波卡黑客松参赛团队齐聚上海，在为期两天的时间中，多场主题演讲、圆桌讨论精彩不断，嘉宾们聚焦波卡生态发展的现状与未来趋势，展开了深度交流与分享。

3. [在波卡生态做项目能得到哪些支持？Parity 怎样帮助生态项目谈下大合作？| Parity EcoDev 团队 AMA](https://mp.weixin.qq.com/s/hqrAzdvinKcBm8e-0dfkzA): 在 2023 Polkadot Decoded 的大会上，Parity 团队成员 Gautam、Nick 和 Ben 开展了一场 AMA 问答，回答了现场观众对波卡生态发展的问题。问答的内容包括在波卡生态构建项目能获得哪些支持，Parity 为平行链团队提供哪些支持，以及波卡接下来六个月的发展重点。

4. [DFG 2023 年上半年 Polkadot 报告](https://mp.weixin.qq.com/s/9wg8nTgbbZoz1VA_rg00gA) 没有一个生态系统能够完全免受宏观经济和市场波动的影响，虽然加密行业还没有完全走出熊市，但 Polkadot 在 2023 年上半年表现出色，Polkadot 社区正在共同打造一个全新的、敏捷的 Polkadot。
   - Polkadot 的开发者活动保持行业领先，活跃账户和社区指标持续增长。
   - 活跃提名池数量翻倍，网络的去中心化性和稳健性进一步提高。
   - OpenGov 于 6 月中旬在 Polkadot 上线，以更加去中心化和高效的方式优化链上治理。
   - XCM V3 已成功合并到 Polkadot 代码库中，并将支持许多高级功能，以及 XCM 传输的显着增长。
   - Polkadot完成7次无缝无分叉升级，主网保持平稳运行。
   - 链接 Polkadot 和 Kusama（简称“Dotsama”）中继链的平行链有 82 条，近 560 个项目部署在 DeFi、基础设施、NFT 市场、游戏、社交平台等赛道，数量正在稳步增长。
   - Gavin Wood 刚刚在 Polkadot Decoded 2023 上重新定义了下一代 Polkadot。Polkadot 将是一台无处不在的超级计算机，它将基于更精细的区块空间而不是链式架构，专注于构建以应用程序为中心的中间件和弹性应用程序 平台，以及更灵活的方法来分配和调度核心计算资源。

## 跨链协议

1. [Xcm-Emulator: 使用 `ext_wrapper` 执行外部性](https://github.com/paritytech/cumulus/pull/2893)：此PR主要关注了如何处理XCM消息的执行。在当前的实现中，如果一个XCM消息被处理，它会触发网络处理所有的XCM通道，这种情况会在使用 `execute_with` 时发生。`ext_wrapper` 将只用测试外部性包装执行。

   以下是主要的变更和讨论内容：

   - XCM消息的处理不应触发网络处理所有的XCM通道，这种情况会在使用 `execute_with` 时发生。`ext_wrapper` 将只用测试外部性包装执行。

   - 使用 `ext_wrapper` 替代 `execute_with`。

   - 在讨论中，贡献者请求添加一些文档/描述到 `fn execute_with<R>(execute: impl FnOnce() -> R) -> R;` 和 `fn ext_wrapper<R>(func: impl FnOnce() -> R) -> R;`，因为它们具有相同的签名，但是了解它们之间的区别是很好的。

2. [XCM兼容性修复针对XCM基准测试](https://github.com/paritytech/cumulus/pull/2934)：此PR主要解决了在polkadot仓库的pallet_xcm基准测试中的一项变更：[Change Fixed to WeightInfoBounds for Polkadot #7077](https://github.com/paritytech/polkadot/pull/7077/files#diff-a4111c7c81a2c886c9cb40df80da8016448148fc24ba109150da006ebad5fcc6R134-R165)， 该变更将`initiate_reserve_withdraw`/`reserve_asset_deposited`从`pallet_xcm_benchmarks_generic.rs`文件移动到`pallet_xcm_benchmarks_fungible.rs`文件。由于伴随者（companion）的CI不会重新生成权重，因此没有为此创建伴随者，此PR修复了这个问题。现在，重新生成权重后，会出现编译错误：https://gitlab.parity.io/parity/mirrors/cumulus/-/jobs/3250422。 此PR部分解决了问题#1974。

   以下是主要的变更和讨论内容：

   - 在讨论中，贡献者对`reserve_asset_deposited`的权重进行了讨论。在当前的实现中，`reserve_asset_deposited`的权重被硬编码为`1_000_000_000_u64`，这并不理想。贡献者建议使用`Weight::MAX`来表示不允许执行此操作。

   - 作者回应说，他们不能立即使用`Weight::MAX`，因为这会破坏`pallet_xcm`的`reserve_transfer_assets`。因此，他们决定暂时回退到硬编码的`1_000_000_000_u64`。

   - 作者还提到，尽管这个PR使得在master分支上重新生成权重变得可能，但是他们仍然需要解决并完成远程权重估计（可能使用“标准XCM权重”）的问题，以及处理以下问题：paritytech/polkadot#7424和paritytech/polkadot#7546。

3. [通过桥梁与pallet xcm进行资产转移](https://github.com/paritytech/cumulus/pull/2762)：此PR与[#2528](https://github.com/paritytech/cumulus/issues/2528)（Kusama/Polkadot的BridgeHub）有关，真正的桥接在此处开始。PR引入了以下内容：

   - 用于在AssetHubKusama和AssetHubPolkadot之间进行桥接的xcm路由配置。

   - 首先，只允许KSM/DOT基于储备进行跨共识AssetHubs的转移，除此之外，不允许其他任何操作（我们先保守一些）。如果我们决定，我们可以允许任何操作（ETH，TrustBackedAssets，ForeignAssets，PoolAssets等）。

   - 有关使用pallet_xcm进行双向模拟limited_reserve_transfer_assets的测试，以及在两侧处理ReserveAssetDeposited。

   - 本地zomienet运行用于：（在此PR中查看parachains/runtimes/bridge-hubs/README.md）

      - 从AHK到AHP的基于储备的KSM转移。

      - 从AHP到AHK的基于储备的DOT转移。

   在讨论中，贡献者对是否应该允许\"ETH，TrustBackedAssets，ForeignAssets，PoolAssets等\"从AssetHubKusama转移到AssetHubPolkadot提出了疑问。作者回应说，他们选择保守的策略，只允许KSM和DOT进行跨共识AssetHubs的储备转移。如果决定，可以允许其他所有操作。